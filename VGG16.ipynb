{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8707d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b935b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 816 images belonging to 2 classes.\n",
      "Found 2412 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val = ImageDataGenerator(rescale = 1/255)\n",
    "val_dataset = val.flow_from_directory('Downloads/train/validation', target_size = (224,224),class_mode = 'binary')\n",
    "\n",
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "train_dataset = train.flow_from_directory('Downloads/train/training', target_size = (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efbfd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=2, activation=\"softmax\"))\n",
    "model.compile(keras.optimizers.Adam(lr=1e-5), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4541024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 17s - loss: 0.7403 - acc: 0.5000\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to vgg16_1.h5\n",
      "10/10 [==============================] - 223s 22s/step - loss: 0.7402 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.7239 - acc: 0.4688\n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 207s 21s/step - loss: 0.7295 - acc: 0.4594 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.6687 - acc: 0.5972\n",
      "Epoch 00003: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 206s 21s/step - loss: 0.6651 - acc: 0.6062 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.6860 - acc: 0.5382\n",
      "Epoch 00004: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 206s 21s/step - loss: 0.6880 - acc: 0.5375 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.7027 - acc: 0.5382\n",
      "Epoch 00005: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 206s 21s/step - loss: 0.6946 - acc: 0.5500 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 15s - loss: 0.6612 - acc: 0.6045\n",
      "Epoch 00006: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 196s 20s/step - loss: 0.6590 - acc: 0.6100 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.6722 - acc: 0.5764\n",
      "Epoch 00007: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 206s 21s/step - loss: 0.6688 - acc: 0.5875 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.6642 - acc: 0.5799\n",
      "Epoch 00008: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 205s 21s/step - loss: 0.6668 - acc: 0.5719 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.6380 - acc: 0.6528\n",
      "Epoch 00009: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 209s 21s/step - loss: 0.6419 - acc: 0.6469 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 16s - loss: 0.6088 - acc: 0.6597\n",
      "Epoch 00010: val_acc did not improve from 0.50000\n",
      "10/10 [==============================] - 205s 20s/step - loss: 0.6157 - acc: 0.6531 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "hist = model.fit_generator(steps_per_epoch=10,generator=train_dataset, validation_data= val_dataset, validation_steps=10,epochs=10,callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d771b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
