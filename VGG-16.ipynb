{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8707d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\spran\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b935b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 816 images belonging to 2 classes.\n",
      "Found 2412 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val = ImageDataGenerator()\n",
    "val_dataset = val.flow_from_directory('Downloads/train/validation', target_size = (224,224),batch_size=50)\n",
    "\n",
    "train = ImageDataGenerator()\n",
    "train_dataset = train.flow_from_directory('Downloads/train/training', target_size = (224,224),batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbfd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters = 512, kernel_size=(3,3), padding='same',activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=(2,2), padding=\"same\"\n",
    "))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.8))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.8))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=2, activation=\"softmax\"))\n",
    "model.compile(keras.optimizers.Adam(lr=0.001), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4541024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.0192 - acc: 0.4882\n",
      "Epoch 00001: val_acc improved from -inf to 0.53600, saving model to vgg16_1.h5\n",
      "10/10 [==============================] - 234s 23s/step - loss: 1.0261 - acc: 0.4958 - val_loss: 7.1359 - val_acc: 0.5360\n",
      "Epoch 2/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.1263 - acc: 0.5693\n",
      "Epoch 00002: val_acc improved from 0.53600 to 0.54200, saving model to vgg16_1.h5\n",
      "10/10 [==============================] - 226s 23s/step - loss: 1.1168 - acc: 0.5740 - val_loss: 7.0230 - val_acc: 0.5420\n",
      "Epoch 3/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.3048 - acc: 0.4475\n",
      "Epoch 00003: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 225s 22s/step - loss: 1.2577 - acc: 0.4543 - val_loss: 6.5748 - val_acc: 0.5200\n",
      "Epoch 4/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.1726 - acc: 0.6198\n",
      "Epoch 00004: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 226s 23s/step - loss: 1.1859 - acc: 0.6062 - val_loss: 5.0007 - val_acc: 0.4500\n",
      "Epoch 5/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.2149 - acc: 0.5054\n",
      "Epoch 00005: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 227s 23s/step - loss: 1.1982 - acc: 0.5026 - val_loss: 2.4520 - val_acc: 0.4580\n",
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.3482 - acc: 0.4607\n",
      "Epoch 00006: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 235s 24s/step - loss: 1.2936 - acc: 0.4651 - val_loss: 2.9262 - val_acc: 0.4680\n",
      "Epoch 7/10\n",
      " 9/10 [==========================>...] - ETA: 15s - loss: 1.2173 - acc: 0.5260\n",
      "Epoch 00007: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 226s 23s/step - loss: 1.2335 - acc: 0.5249 - val_loss: 2.1047 - val_acc: 0.5340\n",
      "Epoch 8/10\n",
      " 9/10 [==========================>...] - ETA: 11s - loss: 1.2317 - acc: 0.5106\n",
      "Epoch 00008: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 193s 19s/step - loss: 1.2001 - acc: 0.5105 - val_loss: 2.3981 - val_acc: 0.5200\n",
      "Epoch 9/10\n",
      " 9/10 [==========================>...] - ETA: 11s - loss: 1.0467 - acc: 0.6240\n",
      "Epoch 00009: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 196s 20s/step - loss: 1.0568 - acc: 0.6147 - val_loss: 1.7930 - val_acc: 0.5160\n",
      "Epoch 10/10\n",
      " 9/10 [==========================>...] - ETA: 14s - loss: 1.2829 - acc: 0.4871\n",
      "Epoch 00010: val_acc did not improve from 0.54200\n",
      "10/10 [==============================] - 231s 23s/step - loss: 1.2298 - acc: 0.4867 - val_loss: 1.5102 - val_acc: 0.5100\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "hist = model.fit_generator(steps_per_epoch=10,generator=train_dataset, validation_data= val_dataset, validation_steps=10,epochs=10,callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d771b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
